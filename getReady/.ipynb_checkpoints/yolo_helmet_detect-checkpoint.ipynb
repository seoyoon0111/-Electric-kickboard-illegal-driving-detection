{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2ec1f8",
   "metadata": {},
   "source": [
    "# Yolo Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe034cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV \n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 파일 경로 읽어오기\n",
    "from glob import glob\n",
    "import time\n",
    "# multi thread\n",
    "import threading\n",
    "# 이미지 가져오기\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "# Sound 출력\n",
    "from gtts import gTTS\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df37d1a",
   "metadata": {},
   "source": [
    "# CNN & OCR Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc5a7e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow : CNN model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import io\n",
    " # OCR Google Cloud api\n",
    "from google.cloud import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22cf300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gTTS 음성파일 만들기\n",
    "# kor_wav = gTTS('주행 불가능 지역입니다', lang = 'ko') \n",
    "# kor_wav.save('impossible.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a2ec5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#google cloud platform\n",
    "# !pip install opencv-contrib-python\n",
    "# !pip install --upgrade google-cloud-vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e968ae50",
   "metadata": {},
   "source": [
    "# Prepare : Yolo weight file, CNN Model load, OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8662faf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 로드\n",
    "model = load_model('cnn_model/cnn_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d11b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 yolo weight파일과 cfg 파일 가져오기\n",
    "net = cv2.dnn.readNet(\"Yolov4/yolov4-obj_1000.weights\", \"Yolov4/yolov4-obj.cfg\") # Helmet : 0, No Helmet : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13fe5731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[243.25575708 143.49997258  19.31426423]\n",
      " [128.85529879  55.75883358 249.92441978]]\n"
     ]
    }
   ],
   "source": [
    "# obj.names : Helmet/No_Helmet\n",
    "classes = []\n",
    "with open(\"Yolov4/obj.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b1645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use google API - json 파일 가져오기\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'OCR/finalproject-375105-31a5d0d9f5a3.json'\n",
    " \n",
    "client_options = {'api_endpoint': 'eu-vision.googleapis.com'}\n",
    "client = vision.ImageAnnotatorClient(client_options=client_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72aa873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ip 주소\n",
    "url = \"https://172.30.106.140:8080/video\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "042d17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty capture folder\n",
    "# CNN capture 폴더 처음에 비워줌\n",
    "for f in glob('capture/*.jpg'):\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4f5eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting default text\n",
    "# global passibility,color \n",
    "# passibility = \"Passibility\"\n",
    "# color = (255, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71a92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080608d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02971613",
   "metadata": {},
   "source": [
    "# Yolov4 Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d430116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티 쓰레드는 영상과 경고음이 충돌하는 것을 막음\n",
    "class Worker(threading.Thread):\n",
    "    def __init__(self):\n",
    "        self.flag = 0\n",
    "        super(Worker, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92cd3624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yolo 헬멧인식 경고음\n",
    "def sound():\n",
    "    display(Audio('sound_file/sounds_warning.wav', autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52fb75bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 도로인식 경고음\n",
    "def sound2():\n",
    "    display(Audio('sound_file/impossible.wav', autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3553b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사진 찍는 함수\n",
    "def take_a_photo():\n",
    "#     url = \"https://172.20.10.5:8080/video\"\n",
    "    cap = cv2.VideoCapture(url)\n",
    "    cv2.namedWindow('camera_screenshot', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    cnt=0\n",
    "    while True:\n",
    "        camera, frame = cap.read()\n",
    "        if not camera:\n",
    "            print(\"Can't read camera\")\n",
    "            break\n",
    "        cv2.imshow('camera_screenshot', frame)\n",
    "\n",
    "    #     now = datetime.datetime.now().strftime(\"%d_%H-%M-%S\")\n",
    "        key = cv2.waitKey(33)\n",
    "\n",
    "        if key == 26:  # ctrl+z\n",
    "            cnt=cnt+1\n",
    "    #         cv2.resize(frame, (416,416))\n",
    "            cv2.imwrite('take_a_photo/capture'+str(cnt)+'.jpg', frame)\n",
    "            print('스크린샷 저장')\n",
    "            # 이미지 크기 조정하여 저장\n",
    "            files = glob('take_a_photo/capture*.jpg')\n",
    "\n",
    "            for f in files:\n",
    "                img = Image.open(f)\n",
    "                img_resize = img.resize((250,250))\n",
    "                title, ext = os.path.splitext(f)\n",
    "                img_resize.save(title+ext)\n",
    "\n",
    "        elif key == 27:  # 종료시 esc\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows() # 스크린샷은 esc 키로 끄기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4562e37e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64399dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "637d7277",
   "metadata": {},
   "source": [
    "# OCR Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8df8440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR 어린이 보호구역 음성파일 만드는 함수\n",
    "def get_narrator(text):\n",
    "    tts = gTTS(text=text, lang='ko')\n",
    "    filename = 'sound_file/narrator.mp3'\n",
    "    tts.save(filename)\n",
    "    \n",
    "    display(Audio(filename, autoplay=True))\n",
    "    \n",
    "# get_narrator(\"어린이 보호구역입니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a905ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR 인식중 '어린이'가 인식되는 경우 \n",
    "def get_text(path):\n",
    "    result = []\n",
    "    \n",
    "    # Load image\n",
    "    with io.open(path, 'rb') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Get text from image\n",
    "    image = vision.Image(content=content)\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    \n",
    "    for text in texts[1:]:\n",
    "        if text.description.isdigit():\n",
    "            if int(text.description) in [x for x in range(20, 90, 10)]:\n",
    "                result.append(text.description)\n",
    "        elif text.description=='어린이':\n",
    "            result.append(text.description)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c62f4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alert_speed_limit(texts):\n",
    "    message = []\n",
    "    digit_boolean = list(map(lambda x: x.isdigit(), texts))\n",
    "    if np.all(digit_boolean):  # 모두 숫자\n",
    "        for text in texts:\n",
    "            message.append(f\"제한속도 시속 {text}km 구간입니다\")\n",
    "    elif np.any(digit_boolean):  # '어린이' 하나 이상 포함\n",
    "        for text in np.array(texts)[digit_boolean]:\n",
    "            message.append(f\"어린이 보호구역입니다. 시속 {text}km로 주행하세요\")\n",
    "    else:\n",
    "        message.append(\"어린이 보호구역입니다\")\n",
    "        \n",
    "    for m in message:\n",
    "        get_narrator(m)  # tts 음성 파일 함수 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d8861a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c04d92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dd0be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1372091",
   "metadata": {},
   "source": [
    "# CNN Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4fd246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_road(model):\n",
    "    df = pd.DataFrame({'image_path': glob('capture/*.jpg')})\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "        df,\n",
    "        x_col='image_path',\n",
    "        y_col='None',\n",
    "        target_size=(250, 250),\n",
    "        class_mode=None,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    pred = model.predict_generator(test_generator)\n",
    "    \n",
    "    return np.argmax(pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca1d19b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 도로인식 함수\n",
    "def CNN():    \n",
    "    global C\n",
    "    passibility = \"Passibility\"\n",
    "    color = (255, 255, 255)\n",
    "\n",
    "    cap = cv2.VideoCapture(url)\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # fps = 25.0\n",
    "\n",
    "    for f in glob('capture/*.jpg'):\n",
    "        os.remove(f)\n",
    "\n",
    "    C=[]\n",
    "    while(True):\n",
    "        camera, frame = cap.read()\n",
    "\n",
    "        # # frame resize\n",
    "        # resize_frame = cv2.resize(frame, (250, 250), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # frame crop & resize\n",
    "        resize_frame = cv2.resize(frame[:, 420:1500], (250, 250), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        if resize_frame is not None:\n",
    "\n",
    "            # Capture 5 images per 1 second\n",
    "            if (int(cap.get(1)) % 5 == 0):\n",
    "                # Save image as 001 ~ 005.jpg\n",
    "                filename = f'{str(len(os.listdir(\"capture\"))%5 + 1).zfill(3)}.jpg'\n",
    "                cv2.imwrite(f'capture/{filename}', resize_frame)\n",
    "\n",
    "                # Get text from image (per 5 seconds)\n",
    "                if (int(cap.get(1)) % 125 == 0):  # 5 * fps\n",
    "                    if get_text(f'capture/{filename}'):\n",
    "                        alert_speed_limit(get_text(f'capture/{filename}'))\n",
    "\n",
    "            if len(os.listdir('capture')) >= 5:\n",
    "                pred = predict_road(model)\n",
    "\n",
    "                if np.all(pred == 1):\n",
    "                    passibility = \"Passible\"\n",
    "                    color = (255, 0, 0)\n",
    "                elif np.all(pred == 0):\n",
    "                    passibility = \"Impassible\"\n",
    "                    color = (0, 0, 255)\n",
    "                    C.append(np.all(pred == 0))  # Append 1 if all of predictions 0\n",
    "\n",
    "                for f in glob('capture/*.jpg'):\n",
    "                    os.remove(f)\n",
    "\n",
    "            cv2.putText(resize_frame, passibility, (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "            cv2.imshow(\"Frame\", resize_frame)\n",
    "\n",
    "        # Detect impassible road more than 5 times -> sound()\n",
    "        if C.count(1) > 4:\n",
    "            sound2() # 불법주행도로 경고음\n",
    "            break\n",
    "\n",
    "        # To finish program(close windows), press q                     \n",
    "        q = cv2.waitKey(1)\n",
    "        if q == ord(\"q\"):\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e00fc00",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9403527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스크린샷 저장\n"
     ]
    }
   ],
   "source": [
    "# 창이 뜨면 ctrl + z로 사진 찍기 -> esc 키로 종료 -> 방금 찍은 사진으로 yolo 실행 -> helmet/no_helmet 인식 \n",
    "# helemt -> CNN 동작 -> q로 종료\n",
    "take_a_photo()\n",
    "\n",
    "# 이미지 불러오기\n",
    "# esc창으로 윈도우 창 닫으면 앞에서 스크린샷 이미지를 불러온다\n",
    "img=glob('take_a_photo/capture*.jpg')\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "# starting_time = time.time()\n",
    "\n",
    "frame_id = 0\n",
    "wList = []\n",
    "for i in range(10):\n",
    "    w = Worker()\n",
    "    wList.append(w)\n",
    "ti=0\n",
    "L = []\n",
    "H = []\n",
    "\n",
    "while True:\n",
    "    frame = cv2.imread(sorted(img)[-1])\n",
    "    frame_id += 1\n",
    "    height, width, channels = frame.shape\n",
    "    # Detecting objects\n",
    "    #416*416 <=== 정확도 조절\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (250, 250), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    # Showing informations on the screen\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                # Object detected\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)   # width of object\n",
    "                h = int(detection[3] * height)\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)       #the starting X position of detected object\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))   #percentage\n",
    "                class_ids.append(class_id)#the name of detected object\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.3)\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = confidences[i]\n",
    "            color = colors[class_ids[i]]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + 30), color, -1)\n",
    "            cv2.putText(frame, label + \" \" + str(round(confidence, 2)), (x, y + 30), font, 3, (255,255,255), 3)\n",
    "    \n",
    "            if class_ids[i] == 1:  # Helmet : 0, No_Helmet : 1\n",
    "                L.append(class_ids[i])\n",
    "                \n",
    "            elif class_ids[i] == 0:\n",
    "                H.append(class_ids[i])\n",
    "                \n",
    "    # 만약 헬멧이 인식되면 프로그램이 끝나고 헬멧을 쓰지 않은 경우는 경고음으로?\n",
    "    # L.count(1)은 프레임 마다 검사를 했을 때, No_Helmet이라고 판단하는 변수가 몇 이상일 때 경보음을 울릴 것인가 경계값을 정하는 변수 \n",
    "    # 노헬멧이 인식된 경우\n",
    "    cv2.imshow(\"Helmet Detection\", frame)\n",
    "    if(L.count(1)>=1): ##confidence 추가\n",
    "        print(\"헬멧 미착용 : \" + str(round(confidence, 2)*100) + \"%\") #헬멧 미착용 인식률\n",
    "        sound()\n",
    "        break\n",
    "\n",
    "    # 헬멧이 인식된 경우 => CNN 모델 추가\n",
    "    elif(H.count(0)>=1):\n",
    "        print('헬멧 착용: '+ str(round(confidence, 2)*100) + \"%\") # 헬멧 착용 인식률\n",
    "        # CNN 모델\n",
    "        CNN()\n",
    "        break\n",
    "        \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):  # q or esc 누르면 창 닫힘\n",
    "        break\n",
    "\n",
    "# cap.release()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21ee6b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96e43783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d20cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
